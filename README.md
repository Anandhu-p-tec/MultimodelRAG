# ğŸ“„ Multimodal RAG â€” Windows Ready (Hugging Face Powered)

A **production-grade Retrieval-Augmented Generation (RAG) system** that ingests PDFs (text, tables, images), summarizes and embeds them into a **Chroma vector database**, and enables **multimodal question answering** via Hugging Face models.  

Built with **Windows compatibility in mind**, it works seamlessly with PDFs containing **text, tables, and images**, and offers both a **Streamlit UI** and **CLI scripts** for interaction.

---
## ğŸ¥ Demo Video

[![Watch the video](https://img.youtube.com/vi/abcd1234/0.jpg)](https://www.youtube.com/watch?v=abcd1234)


## âœ¨ Key Highlights

- ğŸ” **Document parsing**: Extracts text, tables, and images from PDFs (with robust fallbacks).
- ğŸ“ **Summarization**: Generates concise bullet-point summaries for each text/table block.
- ğŸ–¼ **Image understanding**: Supports image captioning with Hugging Face BLIP or OCR fallback.
- ğŸ§  **Embeddings**: Uses **Sentence Transformers** (Hugging Face) for vectorization.
- ğŸ“¦ **Vector store**: Stores embeddings in a persistent **ChromaDB** instance.
- â“ **RAG Retrieval**: Semantic search across multimodal docs with metadata tracking.
- ğŸ’¬ **Answer generation**: Context-aware answers using Hugging Face LLMs.
- ğŸ› **UI + CLI**: Query via a **Streamlit web app** or simple command-line interface.
- ğŸ–¥ **Windows-first**: Includes instructions for Poppler, Tesseract, and Visual C++ build tools.

---

## ğŸ— Architecture

```mermaid
flowchart TD
    A[PDF Upload] --> B[Parser: pdfplumber + fitz + OCR]
    B --> C[Summarizer: HF LLM + BLIP]
    C --> D[Embedder: Sentence Transformers]
    D --> E[Chroma Vector Store]
    E --> F[Retriever]
    F --> G[Answer Generator: Hugging Face LLM]
    G --> H[Streamlit UI / CLI]
```


âš™ï¸ Tech Stack

Language: Python 3.10+

LLMs / Embeddings: Hugging Face (transformers, sentence-transformers)

Vector Database: ChromaDB

PDF Parsing: pdfplumber, PyMuPDF (fitz), optional unstructured

Image Captioning: Hugging Face BLIP, fallback: Tesseract OCR

Frontend: Streamlit

Environment: .env with API/model settings

### ğŸ“‚ Project Structure
```
multimodal-rag/
â”œâ”€ .env.example
â”œâ”€ requirements.txt
â”œâ”€ README.md
â”œâ”€ data/
â”‚  â”œâ”€ docs/            # PDFs + extracted assets
â”‚  â””â”€ chroma_db/       # Persistent Chroma storage
â”œâ”€ pipeline/
â”‚  â”œâ”€ pdf_parser.py    # Text, table, image extraction
â”‚  â”œâ”€ summarizer.py    # Text + image summarization
â”‚  â”œâ”€ embedder.py      # Sentence-transformers embeddings
â”‚  â”œâ”€ vectorstore.py   # ChromaDB wrapper
â”‚  â”œâ”€ retriever.py     # Semantic retrieval
â”‚  â”œâ”€ multimodal_llm.py# Answer generator
â”‚  â””â”€ pipeline.py      # End-to-end coordinator
â”œâ”€ app/
â”‚  â””â”€ streamlit_app.py # UI
â”œâ”€ scripts/
â”‚  â”œâ”€ index_pdf.py     # CLI for indexing
â”‚  â””â”€ query_console.py # CLI for querying
â””â”€ utils/
   â”œâ”€ io_utils.py
   â””â”€ constants.py

```
### Quick Start (Windows)
1. Setup Environment
   ```
    git clone https://github.com/<your-username>/multimodal-rag.git
    cd multimodal-rag
    python -m venv .venv
    .venv\Scripts\activate
    pip install -r requirements.txt
   ```
2. Install External Tools (Windows)

  Poppler â†’ Download
   â†’ add /bin to PATH
  
  Tesseract OCR (optional, for OCR) â†’ Download
  
3. Configure .env
   ```
   cp .env.example .env
    ```
4. Index a PDF
   ```
    python scripts/index_pdf.py ./data/docs/sample.pdf
   ```
6. Query from CLI
```python scripts/query_console.py```


8. Run the Streamlit UI
```streamlit run app/streamlit_app.py --server.port 8501```

### ğŸ“Š Example Workflow

Upload a research paper PDF.

Pipeline:

Extracts text, tables, and images.

Summarizes text and captions images.

Embeds content with Sentence Transformers.

Stores vectors + metadata in ChromaDB.

Ask: â€œSummarize table results from page 3 and explain figure 2.â€

System:

Retrieves relevant summaries + captions.

Generates a concise multimodal answer using Hugging Face LLM.

### ğŸš€ Why This Project Matters

âœ… Demonstrates end-to-end RAG with multimodal support.

âœ… Windows-first setup shows real-world deployability.

âœ… Uses open-source Hugging Face models (cost-efficient, privacy-friendly).

âœ… Clean modular structure for scalability and extension.

âœ… Showcases both backend engineering (pipelines, vector DBs) and frontend integration (Streamlit).

### ğŸ”® Next Steps

Dockerize for cross-platform reproducibility.

Integrate lightweight PEFT/LoRA fine-tuning for domain-specific adaptation.

Add evaluation metrics (retrieval recall, answer faithfulness).

Support hybrid retrieval (sparse + dense).

Extend UI with file history and visualization of embeddings.

### ğŸ‘¨â€ğŸ’» Author

Built with â¤ï¸ by Anandhu p

ğŸ’¼ AI/ML Engineer | Data Science Enthusiast

ğŸŒ Portfolio: [https://github.com/Anandhu-p-tec]

ğŸ“§ Contact: [anandhupadmanabhank@gmail.com]
   

  




